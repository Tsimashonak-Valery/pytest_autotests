"""
–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
"""
import pytest
import json
import csv
from pathlib import Path
from typing import List, Dict, Any
from faker import Faker


class DataProcessor:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö - –ø—Ä–∏–º–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤"""
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.data_dir.mkdir(exist_ok=True)
    
    def save_to_json(self, data: Dict[str, Any], filename: str) -> Path:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ JSON —Ñ–∞–π–ª"""
        file_path = self.data_dir / filename
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return file_path
    
    def load_from_json(self, filename: str) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON —Ñ–∞–π–ª–∞"""
        file_path = self.data_dir / filename
        with open(file_path, "r", encoding="utf-8") as f:
            return json.load(f)
    
    def save_to_csv(self, data: List[Dict], filename: str) -> Path:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ CSV —Ñ–∞–π–ª"""
        file_path = self.data_dir / filename
        if data:
            keys = data[0].keys()
            with open(file_path, "w", newline="", encoding="utf-8") as f:
                writer = csv.DictWriter(f, fieldnames=keys)
                writer.writeheader()
                writer.writerows(data)
        return file_path
    
    def load_from_csv(self, filename: str) -> List[Dict]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ CSV —Ñ–∞–π–ª–∞"""
        file_path = self.data_dir / filename
        with open(file_path, "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            return list(reader)
    
    def transform_data(self, data: List[Dict]) -> List[Dict]:
        """–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö - –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤—ã—á–∏—Å–ª—è–µ–º—ã—Ö –ø–æ–ª–µ–π"""
        for item in data:
            if "price" in item and "quantity" in item:
                item["total"] = float(item["price"]) * int(item["quantity"])
            if "first_name" in item and "last_name" in item:
                item["full_name"] = f"{item['first_name']} {item['last_name']}"
        return data
    
    def filter_data(self, data: List[Dict], **filters) -> List[Dict]:
        """–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö –ø–æ –∑–∞–¥–∞–Ω–Ω—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""
        result = data
        for key, value in filters.items():
            result = [item for item in result if item.get(key) == value]
        return result


class TestDataProcessorIntegration:
    """–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã –¥–ª—è DataProcessor"""
    
    @pytest.fixture
    def temp_data_dir(self, tmp_path):
        """–í—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        return tmp_path / "test_data"
    
    @pytest.fixture
    def processor(self, temp_data_dir):
        """–≠–∫–∑–µ–º–ø–ª—è—Ä DataProcessor"""
        return DataProcessor(temp_data_dir)
    
    @pytest.fixture
    def sample_products(self, faker_instance):
        """–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ - –ø—Ä–æ–¥—É–∫—Ç—ã"""
        products = []
        for i in range(10):
            products.append({
                "id": i + 1,
                "name": faker_instance.catch_phrase(),
                "price": faker_instance.random_number(digits=3),
                "quantity": faker_instance.random_int(min=1, max=100),
                "category": faker_instance.random_element(["electronics", "clothing", "food"])
            })
        return products
    
    @pytest.fixture
    def sample_users(self, faker_instance):
        """–¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏"""
        users = []
        for i in range(5):
            users.append({
                "id": i + 1,
                "first_name": faker_instance.first_name(),
                "last_name": faker_instance.last_name(),
                "email": faker_instance.email(),
                "city": faker_instance.city()
            })
        return users
    
    # ============== –¢–µ—Å—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ ==============
    
    @pytest.mark.integration
    def test_save_and_load_json(self, processor, sample_products):
        """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ JSON"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        file_path = processor.save_to_json(
            {"products": sample_products}, 
            "products.json"
        )
        
        assert file_path.exists()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        loaded_data = processor.load_from_json("products.json")
        
        assert "products" in loaded_data
        assert len(loaded_data["products"]) == len(sample_products)
        assert loaded_data["products"] == sample_products
    
    def test_save_and_load_csv(self, processor, sample_users):
        """–¢–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∑–∫–∏ CSV"""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∞–Ω–Ω—ã–µ
        file_path = processor.save_to_csv(sample_users, "users.csv")
        
        assert file_path.exists()
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        loaded_data = processor.load_from_csv("users.csv")
        
        assert len(loaded_data) == len(sample_users)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é –∑–∞–ø–∏—Å—å
        # –ß–∏—Å–ª–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ CSV —Å—Ç–∞–Ω–æ–≤—è—Ç—Å—è —Å—Ç—Ä–æ–∫–∞–º–∏
        assert loaded_data[0]["first_name"] == sample_users[0]["first_name"]
        assert loaded_data[0]["email"] == sample_users[0]["email"]
    
    # ============== –¢–µ—Å—Ç—ã —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö ==============
    
    def test_transform_products_adds_total(self, processor, sample_products):
        """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–ª—è total –∫ –ø—Ä–æ–¥—É–∫—Ç–∞–º"""
        transformed = processor.transform_data(sample_products.copy())
        
        for product in transformed:
            assert "total" in product
            expected_total = product["price"] * product["quantity"]
            assert product["total"] == expected_total
    
    def test_transform_users_adds_full_name(self, processor, sample_users):
        """–¢–µ—Å—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –ø–æ–ª—è full_name –∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º"""
        transformed = processor.transform_data(sample_users.copy())
        
        for user in transformed:
            assert "full_name" in user
            expected_name = f"{user['first_name']} {user['last_name']}"
            assert user["full_name"] == expected_name
    
    # ============== –¢–µ—Å—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ==============
    
    def test_filter_by_category(self, processor, sample_products):
        """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø—Ä–æ–¥—É–∫—Ç–æ–≤ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        electronics = processor.filter_data(
            sample_products, 
            category="electronics"
        )
        
        for product in electronics:
            assert product["category"] == "electronics"
    
    def test_filter_by_multiple_criteria(self, processor, sample_products):
        """–¢–µ—Å—Ç —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""
        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        sample_products[0]["category"] = "electronics"
        sample_products[0]["quantity"] = 50
        
        filtered = processor.filter_data(
            sample_products,
            category="electronics",
            quantity=50
        )
        
        assert len(filtered) >= 1
        assert all(p["category"] == "electronics" for p in filtered)
        assert all(p["quantity"] == 50 for p in filtered)
    
    # ============== –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã ==============
    
    @pytest.mark.integration
    @pytest.mark.slow
    def test_full_data_pipeline(self, processor, sample_products):
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
        # 1. –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        transformed = processor.transform_data(sample_products.copy())
        
        # 2. –§–∏–ª—å—Ç—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        filtered = processor.filter_data(
            transformed, 
            category=sample_products[0]["category"]
        )
        
        # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        json_path = processor.save_to_json(
            {"filtered_products": filtered}, 
            "filtered.json"
        )
        
        # 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ CSV
        csv_path = processor.save_to_csv(filtered, "filtered.csv")
        
        # 5. –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º
        json_data = processor.load_from_json("filtered.json")
        csv_data = processor.load_from_csv("filtered.csv")
        
        assert json_path.exists()
        assert csv_path.exists()
        assert len(json_data["filtered_products"]) == len(filtered)
        assert len(csv_data) == len(filtered)
    
    def test_empty_data_handling(self, processor):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        empty_list = []
        
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        transformed = processor.transform_data(empty_list)
        assert transformed == []
        
        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        filtered = processor.filter_data(empty_list, any_field="value")
        assert filtered == []
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—É—Å—Ç—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        csv_path = processor.save_to_csv(empty_list, "empty.csv")
        assert csv_path.exists()
    
    def test_data_consistency_across_formats(self, processor, sample_users):
        """–¢–µ—Å—Ç –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –º–µ–∂–¥—É —Ñ–æ—Ä–º–∞—Ç–∞–º–∏"""
        # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        transformed = processor.transform_data(sample_users.copy())
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –æ–±–∞ —Ñ–æ—Ä–º–∞—Ç–∞
        processor.save_to_json({"users": transformed}, "users.json")
        processor.save_to_csv(transformed, "users.csv")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—Ä–∞—Ç–Ω–æ
        json_users = processor.load_from_json("users.json")["users"]
        csv_users = processor.load_from_csv("users.csv")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å
        assert len(json_users) == len(csv_users)
        
        for i, (json_user, csv_user) in enumerate(zip(json_users, csv_users)):
            # CSV –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –∫–∞–∫ —Å—Ç—Ä–æ–∫–∏, –ø–æ—ç—Ç–æ–º—É —Å—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –ø–æ–ª—è
            assert json_user["first_name"] == csv_user["first_name"]
            assert json_user["last_name"] == csv_user["last_name"]
            assert json_user["email"] == csv_user["email"]
            assert json_user["full_name"] == csv_user["full_name"]
    
    @pytest.mark.parametrize("num_records", [10, 100, 1000])
    def test_performance_with_different_data_sizes(self, processor, faker_instance, num_records):
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å —Ä–∞–∑–Ω—ã–º–∏ –æ–±—ä–µ–º–∞–º–∏ –¥–∞–Ω–Ω—ã—Ö"""
        import time
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
        large_dataset = [
            {
                "id": i,
                "name": faker_instance.name(),
                "value": faker_instance.random_number()
            }
            for i in range(num_records)
        ]
        
        # –ó–∞–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
        start_time = time.time()
        
        processor.save_to_json({"data": large_dataset}, f"large_{num_records}.json")
        loaded = processor.load_from_json(f"large_{num_records}.json")
        
        elapsed_time = time.time() - start_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        assert len(loaded["data"]) == num_records
        assert elapsed_time < 5  # –î–æ–ª–∂–Ω–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å—Å—è –º–µ–Ω–µ–µ —á–µ–º –∑–∞ 5 —Å–µ–∫—É–Ω–¥


class TestDataValidation:
    """–¢–µ—Å—Ç—ã –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–∞–Ω–Ω—ã—Ö"""
    
    @pytest.fixture
    def processor(self, tmp_path):
        return DataProcessor(tmp_path / "validation_test")
    
    def test_invalid_json_handling(self, processor, tmp_path):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–µ–≤–∞–ª–∏–¥–Ω–æ–≥–æ JSON"""
        # –°–æ–∑–¥–∞–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON —Ñ–∞–π–ª
        invalid_file = processor.data_dir / "invalid.json"
        invalid_file.write_text("{ invalid json }")
        
        with pytest.raises(json.JSONDecodeError):
            processor.load_from_json("invalid.json")
    
    def test_missing_file_handling(self, processor):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–µ–≥–æ —Ñ–∞–π–ª–∞"""
        with pytest.raises(FileNotFoundError):
            processor.load_from_json("nonexistent.json")
    
    def test_unicode_data_handling(self, processor):
        """–¢–µ—Å—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ Unicode –¥–∞–Ω–Ω—ã—Ö"""
        unicode_data = {
            "—Ä—É—Å—Å–∫–∏–π": "—Ç–µ–∫—Å—Ç",
            "‰∏≠Êñá": "ÊñáÂ≠ó",
            "emoji": "üòÄüéâ",
            "special": "¬©¬Æ‚Ñ¢"
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º
        processor.save_to_json(unicode_data, "unicode.json")
        loaded = processor.load_from_json("unicode.json")
        
        assert loaded == unicode_data